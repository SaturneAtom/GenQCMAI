from dotenv import load_dotenv
from PyPDF2 import PdfReader
import streamlit as st
from langchain.text_splitter import CharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores.faiss import FAISS
from langchain.chains.question_answering import load_qa_chain
from langchain_openai import OpenAI
from langchain_community.callbacks import get_openai_callback
from langchain.output_parsers import CommaSeparatedListOutputParser
from langchain.prompts import PromptTemplate

st.set_page_config(
    page_title="Mon app",
    page_icon="üëã",
)
# Load environment variables
load_dotenv()

# D√©claration des variables globales pour stocker les r√©sultats de g√©n√©ration
result_multiple_choices_generation = None
result_one_choice_generation = None
result_text_trou_generation = None

output_parser = CommaSeparatedListOutputParser()

# Define the function JSON for quiz generation

def process_text(text):
    # Split the text into chunks using Langchain's CharacterTextSplitter
    text_splitter = CharacterTextSplitter(
        separator="\n",
        chunk_size=1000,
        chunk_overlap=300,
        length_function=len
    )
    chunks = text_splitter.split_text(text)
    
    # Convert the chunks of text into embeddings to form a knowledge base
    embeddings = OpenAIEmbeddings()
    knowledgeBase = FAISS.from_texts(chunks, embeddings)
    
    return knowledgeBase

def get_format_instructions():
    return output_parser.get_format_instructions()

def format_messages(text, format_instructions):
    # Format the messages here as per your requirement
    return f"{text}\n\n{format_instructions}"

def run_chain(docs, query_list_questions):
    # Initialise LLM
    llm = OpenAI(
        model="gpt-3.5-turbo-instruct",
        temperature=0.5,
        max_tokens=250,
        top_p=1.0,
        frequency_penalty=0.5,
        presence_penalty=0.0
    )

    # Initialise QA Chain
    chain = load_qa_chain(llm)

    multiple_choice = PromptTemplate(
    template="List five {subject}.\n{format_instructions}",
    input_variables=["subject"],
    partial_variables={"format_instructions": format_instructions}
    )


    # Get the formatted messages
    format_instructions = get_format_instructions()
    messages = format_messages(query_list_questions, format_instructions)

    # Run the chain and get the response
    with get_openai_callback() as cost:
        chat_response = chain.run(input_documents=docs, question=messages)
        print(cost)
    
     # Parse the response content
    if isinstance(chat_response, str):
        response_content = chat_response
    else:
        response_content = chat_response.content
    
    output_dict = output_parser.parse(response_content)

    return output_dict

def main():
    global result_multiple_choices_generation, result_text_trou_generation, result_one_choice_generation
    
    query_text_trou = "En tant que professeur d'universit√© enseignant un cours bas√© sur le document fourni, cr√©ez 3 exercices √† trou pour aider les √©tudiants √† mieux comprendre le contenu. Assurez-vous que chaque exercice pr√©sente une phrase tir√©e du document avec des mots manquants, que les √©tudiants devront remplir avec des concepts cl√©s, des termes sp√©cifiques ou des exemples pertinents. Format de sortie : une liste de 3 phrases avec des trous √† remplir par les √©tudiants."
    query_multiple_semantic = """Je dispose d'un document PDF qui contient des informations sur [sujet sp√©cifique du document]. Je veux cr√©er des exercices √† choix multiple bas√©s sur le contenu de ce document. Voici les √©tapes et les consignes sp√©cifiques :
    Analyse du document : Identifiez les points cl√©s et les informations importantes dans le document."""
    query_multiple_choice = """
        Cr√©ation des questions : Formulez 2 questions claires et pr√©cises bas√©es sur ces points cl√©s. Chaque question doit √™tre con√ßue pour tester la compr√©hension des informations importantes contenues dans le document.
        Options de r√©ponse :
        Fournissez quatre options de r√©ponse pour chaque question.
        Important : Assurez-vous que chaque question √† plusieurs r√©ponse (au moins deux r√©ponses correctes)
        Les options incorrectes (distracteurs) doivent √™tre plausibles mais incorrectes.
        Format :
        Utilisez le format suivant pour chaque question :
        Question : [Ins√©rez la question ici]
        -
        Options :
        - a) [Option 1]
        - b) [Option 2]
        - c) [Option 3]
        - d) [Option 4]
        
        R√©ponse correcte : [Indiquez les lettre des r√©ponse correcte]
        Exemple :

        Question : Quelle ville sont fran√ßaise ?
        -
        Options :
        - a) Berlin
        - b) Bordeaux
        - c) Paris
        - d) Rome
        
        - R√©ponse correcte : b, c

    """
    query_one_choice = """
        Cr√©ation des questions : Formulez 2 questions claires et pr√©cises bas√©es sur ces points cl√©s. Chaque question doit √™tre con√ßue pour tester la compr√©hension des informations importantes contenues dans le document.
        Options de r√©ponse :
        Fournissez quatre options de r√©ponse pour chaque question.
        Important : Assurez-vous que chaque question a une seule bonne r√©ponse.
        Les options incorrectes (distracteurs) doivent √™tre plausibles mais incorrectes.
        Format :
        Utilisez le format suivant pour chaque question :
        Question : [Ins√©rez la question ici]
        -
        Options :
        - a) [Option 1]
        - b) [Option 2]
        - c) [Option 3]
        - d) [Option 4]
        
        R√©ponse correcte : [Indiquez la lettre des r√©ponse correcte]
        Exemple :

        Question : Quelle est la capitale de la France ?
        -
        Options :
        - a) Berlin
        - b) Madrid
        - c) Paris
        - d) Rome
        
        - R√©ponse correcte : c
    """

    st.header("Cr√©ation d'exercices avec IA üìö")
    st.subheader("Bienvenue dans l'outil de cr√©ation d'exercices automatis√© √† partir de pdf ! üöÄ")

   
    pdf = st.file_uploader('Veuillez t√©l√©charger un document PDF pour commencer', type='pdf', key="pdf_uploader")
    
    if pdf is not None:
        pdf_reader = PdfReader(pdf)
        text = ""
        for page in pdf_reader.pages:
            text += page.extract_text()
        
        knowledgeBase = process_text(text)
        
        st.success('Pdf enregistr√©!', icon="‚úÖ")

        st.divider()

        tab1, tab2, tab3 = st.tabs(["Cr√©er questions √† choix multiple", "Cr√©er un exercice de texte √† trous", "Cr√©er questions √† choix unique"])    
       
        with tab1:    
            if st.button("G√©n√©rer liste de questions", key="list_questions_key"):
                if result_multiple_choices_generation is None:
                    docs = knowledgeBase.similarity_search(query_multiple_semantic)
                    llm = OpenAI(
                        model="gpt-3.5-turbo-instruct",
                        temperature=0.5,
                        max_tokens=1000,
                        top_p=1.0,
                        frequency_penalty=0.5,
                        presence_penalty=0.0
                    )
                    chain = load_qa_chain(llm)
                    with get_openai_callback() as cost:
                        result_multiple_choices_generation = chain.run(input_documents=docs, question=query_multiple_choice)
                        print(cost)
                st.write(result_multiple_choices_generation)

        with tab2:
            if st.button("G√©n√©rer texte √† trous", key="text_trou_key"):
                if result_text_trou_generation is None:
                    docs = knowledgeBase.similarity_search(query_multiple_semantic)
                    llm = OpenAI(
                        model="gpt-3.5-turbo-instruct",
                        temperature=0.5,
                        max_tokens=250,
                        top_p=1.0,
                        frequency_penalty=0.5,
                        presence_penalty=0.0
                    )
                    chain = load_qa_chain(llm, chain_type="stuff")
                    with get_openai_callback() as cost:
                        result_text_trou_generation = chain.run(input_documents=docs, question=query_text_trou)
                        print(cost)
                st.write(result_text_trou_generation)

        with tab3:
            if st.button("G√©n√©rer question √† choix unique", key="one_choice_key"):
                if result_one_choice_generation is None:
                    docs = knowledgeBase.similarity_search(query_multiple_semantic)
                    llm = OpenAI(
                        model="gpt-3.5-turbo-instruct",
                        temperature=0.5,
                        max_tokens=250,
                        top_p=1.0,
                        frequency_penalty=0.5,
                        presence_penalty=0.0
                    )
                    chain = load_qa_chain(llm, chain_type='stuff')
                    with get_openai_callback() as cost:
                        result_one_choice_generation = chain.run(input_documents=docs, question=query_one_choice)
                        print(cost)
                print(result_one_choice_generation)
                st.write(result_one_choice_generation)
           
if __name__ == "__main__":
    main()

